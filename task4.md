Как проблема проявляется

В контроллере утечки памяти используется статический список, в который постоянно добавляются массивы байт. Память растёт, GC срабатывает всё чаще, но после сборки heap почти не освобождается. В пике это может привести к OutOfMemoryError и падению сервиса.

Почему это важно

Опасность в паузах GC и полном отказе сервиса. При Full GC все потоки останавливаются, время ответа легко вырастает с десятков миллисекунд до нескольких сотен. Для REST API это критично, особенно под нагрузкой.

Как обнаружить и предотвратить

Включить логирование GC (-Xlog:gc*:file=gc.log:time,level,tags) и смотреть частоту Full GC и объём освобождённой памяти.

Снять heap dump по OutOfMemoryError и проанализировать в VisualVM или Eclipse MAT, кто держит память.

В мониторинге смотреть метрики GC и использования heap (Actuator + Prometheus + Grafana).

В коде избегать статических коллекций для бизнес‑данных, ограничивать кеши по размеру и TTL, добавлять явную очистку.

2. Контекстное переключение (слишком много потоков)
   Как проблема проявляется

При нагрузке в десятки одновременных пользователей обычные потоки Tomcat блокируются на Thread.sleep в контроллерах. Пул потоков быстро заполняется, растут очереди, увеличивается среднее время ответа. CPU тратит всё больше времени на переключение контекста.

Почему это важно

Чем больше активных блокирующих потоков, тем больше overhead на переключение и расход памяти под стеки. Это не даёт линейно масштабировать сервис по числу пользователей. Под нагрузкой латентность растёт гораздо быстрее, чем нагрузка.

Как обнаружить и предотвратить

Нагрузочный сценарий в JMeter: увеличивать число пользователей и смотреть, как растёт среднее и 95‑й перцентиль времени ответа.

Метрики пула потоков (busy vs max), графики latency и throughput в Grafana.

В профайлере и мониторинге — графики количества потоков, времени в состоянии BLOCKED/WAITING.

Для предотвращения: включить виртуальные потоки, ограничить задержки, не блокировать потоки на ожидании I/O, при необходимости использовать асинхронные/реактивные контроллеры.

3. Алгоритмический уровень (работа с данными)
   Как проблема проявляется

Метод получения всех задач создаёт новый список из значений ConcurrentHashMap. Это операция O(n) по времени и памяти. При сотнях и тысячах задач время ответа и объём аллокаций растут линейно. Под нагрузкой это усиливает давление на GC и увеличивает задержки.

Почему это важно

Алгоритм, который нормально работает на 100 элементах, может стать бутылочным горлышком на 10 000. Без пагинации и оптимизации клиент будет получать всё более тяжёлые ответы, а сервер — всё сильнее тормозить.

Как обнаружить и предотвратить

Прогнать JMeter с разным объёмом данных и сравнить время ответа для GET /tasks.

Использовать бенчмарки (JMH) для метода, который формирует ответ, и измерять деградацию при росте n.

В профайлере смотреть, какие методы занимают больше всего CPU и создают больше всего объектов.

Для предотвращения: добавить пагинацию, не копировать коллекции без необходимости, при переходе к БД — использовать индексы и постраничные запросы, а не выборку всех строк.