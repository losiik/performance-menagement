Краткое описание результатов
В качестве «горячих» данных выбраны ответы для GET /api/tasks (список задач) и GET /api/tasks/{id} (детали задачи), так как они вызываются чаще всего и меняются редко.

Для локального кэша использован Caffeine с TTL 10 минут и аннотациями @Cacheable / @CacheEvict, что уменьшило время повторного запроса с сотен миллисекунд (эмуляция БД) до единиц миллисекунд за счёт хранения данных в памяти процесса.

Для распределённого кэша использован Redis с тем же TTL: первый запрос немного медленнее из‑за записи в Redis, но повторные запросы быстрее БД и доступны всем инстансам сервиса.

При запуске двух экземпляров сервиса:

С Caffeine каждый инстанс имеет свой кэш: первый запрос на каждом инстансе идёт в «БД», кэш не общий.

С Redis оба инстанса используют общий кэш: после прогрева на одном инстансе второй сразу получает данные из Redis.

Инвалидация через @CacheEvict при создании, обновлении и удалении задач корректно очищает кэш, предотвращая возврат устаревших данных.

Выводы
Локальный кэш Caffeine даёт минимальное время ответа при повторных запросах и прост в настройке, но подходит только для одного инстанса или когда расхождение данных между инстансами не критично.

Redis обеспечивает общий кэш для нескольких экземпляров и устойчивее в многосервисной/кластерной архитектуре, но добавляет сетевой оверхед и усложняет инфраструктуру.

В сценарии одного инстанса оптимален Caffeine; при масштабировании на несколько инстансов или микросервисы целесообразно использовать Redis или гибрид: локальный кэш поверх распределённого.
