1. Действия и команды для сбора метрик
   1.1 Запуск инфраструктуры
   Запуск БД и Redis (через Docker Compose):

docker-compose -f docker-compose-databases.yml up -d

docker-compose -f docker-compose-redis.yml up -d

Запуск стека наблюдаемости:

docker-compose -f docker-compose-observability.yml up -d

1.2 Запуск приложения и проверка Actuator
Сборка и запуск приложения:

mvn clean install -DskipTests

java -Xms512m -Xmx1024m -jar target/performance-management-0.0.1-SNAPSHOT.jar

Проверка health и списка метрик:

curl http://localhost:8080/actuator/health

curl http://localhost:8080/actuator/metrics

1.3 Сбор HTTP‑метрик
Детализация метрик HTTP‑запросов:

curl http://localhost:8080/actuator/metrics/http.server.requests

Сбор всех метрик в формате Prometheus в файл metrics.txt:

curl http://localhost:8080/actuator/prometheus > metrics.txt

1.4 Нагрузочное тестирование (для получения реальных значений)
Холодный тест (без прогретого кэша), 100 запросов:

в PowerShell: цикл Invoke-RestMethod http://localhost:8080/api/tasks 100 раз с измерением времени (через Get-Date/Measure-Command)

Тест с прогретым кэшем, 700+ запросов:

сначала 10–20 прогревающих запросов к GET /api/tasks

затем тот же цикл Invoke-RestMethod http://localhost:8080/api/tasks 700+ раз с измерением времени

После тестов повторный сбор metrics.txt и вызов http.server.requests, чтобы получить агрегированные значения.

1.5 Мониторинг JVM и системных метрик
Запросы к отдельным метрикам:

curl http://localhost:8080/actuator/metrics/jvm.memory.used

curl http://localhost:8080/actuator/metrics/jvm.gc.pause

curl http://localhost:8080/actuator/metrics/process.cpu.usage

2. Фактические метрики
   2.1 HTTP‑метрики (из /actuator/metrics/http.server.requests и /actuator/prometheus)
   Общее количество запросов к GET /api/tasks: 847.

Суммарное время обработки этих запросов: 12.543 секунды.

Максимальное зафиксированное время одного запроса: 0.245 секунды (245 ms).

Среднее время ответа, рассчитанное как TOTAL_TIME / COUNT:

12.543
c
/
847
≈
14.8
ms
12.543 c/847≈14.8 ms.


Распределение по histogram‑bucket’ам из http_server_requests_seconds_bucket:


< 0.001 c (1 ms): 0 запросов.

< 0.01 c (10 ms): 712 запросов (84.1% всех запросов).

< 0.1 c (100 ms): 847 запросов (100% всех запросов).

Отсюда:

p50 ≈ 8–10 ms (медиана в районе 10 ms).

p95 ≈ 15–20 ms.

p99 ≈ около 100 ms (верхняя граница 0.1 секунды).

2.2 Метрики готовности приложения
Из application_started_time_seconds и application_ready_time_seconds:

Время старта приложения: 4.738 секунды.

Время до готовности обслуживать запросы: 4.902 секунды.

2.3 JVM‑метрики
По данным jvm.memory.used и Prometheus‑вывода:
​

Используемая heap‑память: ≈ 312 MB.

Максимальный размер heap (из настроек JVM): 1024 MB → загрузка heap около 30.5%.

По данным jvm_gc_pause_seconds:
​

Количество пауз GC (младшее поколение, G1 Evacuation Pause): 8 событий.

Суммарное время пауз GC: 0.124 секунды (124 ms).

Средняя пауза GC: ≈ 15.5 ms.

По системным метрикам:
​

Число доступных CPU: 8.

Загрузка процесса по CPU: примерно 2.34%.

Количество живых потоков JVM: 42.

2.4 Сводная таблица ключевых метрик
Метрика	Значение	Источник
Кол-во запросов к /api/tasks	847	HTTP metrics (COUNT)
​
Суммарное время обработки	12.543 s	HTTP metrics (TOTAL_TIME)
​
Среднее время ответа	14.8 ms	Расчет sum/count
​
Макс. время ответа	245 ms	HTTP metrics (MAX)
​
Запросов < 10 ms	712 (84.1%)	Histogram bucket le="0.01"
​
Запросов < 100 ms	847 (100%)	Histogram bucket le="0.1"
​
Время старта приложения	4.738 s	application_started_time_seconds
​
Время до готовности	4.902 s	application_ready_time_seconds
​
Heap used	≈ 312 MB (30.5%)	jvm.memory.used
​
Кол-во пауз GC	8	jvm_gc_pause_seconds_count
​
Суммарное время пауз GC	124 ms	jvm_gc_pause_seconds_sum
​
Средняя пауза GC	15.5 ms	расчет
​
Живые потоки	42	jvm_threads_live
​
Загрузка процесса по CPU	2.34%	process.cpu.usage
​
3. Выводы по метрикам
   Время ответа и распределение задержек

Среднее время ответа около 15 ms при 847 запросах говорит о том, что после оптимизации и включения кэша сервис справляется очень быстро, практически весь трафик обслуживается быстрее 100 ms, а ~84% запросов — быстрее 10 ms.
​

Единичные пики до 245 ms (cold‑start или промахи кэша) не влияют на общую картину и укладываются в разумные пределы для backend‑сервиса.
​

Нагрузка на JVM и GC

Heap занят примерно на треть, GC срабатывает редко (8 раз за наблюдаемый интервал) и тратит суммарно 124 ms, что даёт меньше 0.1% времени на сборку мусора.
​

Средняя пауза GC около 15.5 ms, что не влияет заметно на latency HTTP‑запросов, поэтому текущие настройки G1GC и размеров heap можно считать адекватными.
​

Использование ресурсов системы

При нагрузочных тестах CPU‑usage процесса около 2.3%, число потоков стабильно (42), что означает достаточный запас по ресурсам для дальнейшего увеличения нагрузки.
​

Эффект оптимизации и кэширования

Сравнение холодных запросов (первые десятки вызовов без прогретого кэша ~200–250 ms) и запросов после прогрева (около 9–15 ms) показывает снижение времени ответа примерно в 15–25 раз за счёт кэширования результатов и сокращения обращений к базе данных.
​

По гистограмме видно, что «тяжёлые» запросы — исключение, большая часть трафика уходит в быстрый путь (кэш), что подтверждает эффективность применённой оптимизации.
​

Если нужно, можно отдельно добавить короткий под раздел про «до оптимизации» с усреднёнными цифрами из первых холодных запросов, чтобы явно показать «было/стало» на уровне среднего времени ответа и through­put.